[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sohail’s Portfolio",
    "section": "",
    "text": "Welcome\nWelcome to my portfolio! I am Sohail, an aspiring Data Scientist, and I’m passionate about understanding the flow of data from the bottom up — from data generation to AI/ML. Check out my Data Science, Machine Learning, and Data Engineering Projects. I would love your feedback, let’s connect to grow together.\nPlease, use the side bar on the left for navigation.\n\nCode# &lt;div style=\"display:flex; justify-content:space-between; align-items:center;\"&gt;\n #  &lt;img src=\"assets/Collage.png\"  alt=\"Data Viz 1\" style=\"width:100%;\"&gt;\n# &lt;/div&gt;\n\n\n\n\n\nLet’s Connect!\n\n\nI’d love to connect—feel free to reach out anytime\n\n\nEmail GitHub LinkedIn",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html",
    "href": "src/pv/pv-01.html",
    "title": "Recreated Original New York Times Graphic visualization",
    "section": "",
    "text": "Original Graphic here",
    "crumbs": [
      "Data Science Projects",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Recreated Original New York Times Graphic visualization</span>"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html#what-the-visualization-contains",
    "href": "src/pv/pv-01.html#what-the-visualization-contains",
    "title": "Recreated Original New York Times Graphic visualization",
    "section": "What the Visualization contains",
    "text": "What the Visualization contains\n\nTemperature graph\n\nBands for the record, normal, and actual highs and lows are shown in the correct colors.\nDownward triangles point to the record high temperatures above the red band.\nText displays the record high temperatures above the triangles.\nX-axis label: 3-letter month abbreviations appear in the middle of each month.\nY-axis label: Tick marks at 0, 40, 80, and 120 only.\nVertical lines separate the months.\nTitle of “Temperature” is included.\n\n\nPrecipitation\n\nTan area and blue line reflecting the monthly cumulative precipitation is included.\nText (number) for cumulative precipitation for each month is included at the end of each month just above the blue line.\nDownward triangles point to the record precipitation days.\nVertical lines separate the months.\nTitle of “Precipitation” is included.\n\n\nOverall\n\nBoth the temperature and precipitation graphs are in one figure.\nThe temperature plot takes up more vertical space than the precipitation plot.\nThe title “SFO weather in 2011” is present.",
    "crumbs": [
      "Data Science Projects",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Recreated Original New York Times Graphic visualization</span>"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html#setup",
    "href": "src/pv/pv-01.html#setup",
    "title": "Recreated Original New York Times Graphic visualization",
    "section": "Setup",
    "text": "Setup\n\nCode# Code for loading packages and reading in data\nlibrary(tidyverse)\nweather &lt;- read_csv(\"https://mac-stat.github.io/data/sfo_weather.csv\")\nhead(weather)\n\n# A tibble: 6 × 19\n  Month   Day   Low  High NormalLow NormalHigh RecordLow LowYr RecordHigh HiYear\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1     1     1    47    52        44         56        31  1965         68   1996\n2     1     2    48    51        44         56        29  1960         69   1996\n3     1     3    45    53        44         56        31  1950         69   2000\n4     1     4    39    53        44         56        29  1949         62   2006\n5     1     5    38    55        44         56        26  1949         65   1986\n6     1     6    37    52        44         56        29  1950         66   2003\n# ℹ 9 more variables: Precip &lt;dbl&gt;, RecordPrecip &lt;dbl&gt;, PrecipYr &lt;dbl&gt;,\n#   date &lt;date&gt;, dateInYear &lt;dbl&gt;, Record &lt;lgl&gt;, RecordText &lt;chr&gt;,\n#   RecordP &lt;lgl&gt;, CulmPrec &lt;dbl&gt;",
    "crumbs": [
      "Data Science Projects",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Recreated Original New York Times Graphic visualization</span>"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html#visualization",
    "href": "src/pv/pv-01.html#visualization",
    "title": "Recreated Original New York Times Graphic visualization",
    "section": "Visualization",
    "text": "Visualization\n\nCode# Code for recreating the visualization\n# Use as many code chunks as you need to organize your work well\n\n\nCreating the basic plot\n\nCode# geom_linerange basically allows to plot range data (two values of y: low and max with 1 x value )\nbasic_plt &lt;-ggplot(weather, aes(x = dateInYear, ymin = weather$RecordLow, ymax = weather$RecordHigh)) + \n          geom_linerange(color = \"#ECEBE3\")+ scale_y_continuous(limits = c(0, 120), breaks = c(0, 40, 80, 120)) +         theme_classic() \n\nbasic_plt\n\n\n\n\n\n\n\nAdding normal and weather lows and highs\n\nCode# to add new layer representing more y values, we just use + and continue adding layers (no seperate operator in ggplot). \n# adding new layers of normal and record lows\n# just add + to add layers on saved basic plt, no need to pipe as we are just adding layers not saying \"and then\"\n\nnormal_record_plt &lt;-basic_plt +\n  geom_linerange(color =\"#C8B8BA\", aes(ymin = weather$NormalLow, ymax = weather$NormalHigh)) +\n  geom_linerange(color = \"#A90248\", alpha = 1,  aes(ymin = weather$Low, ymax = weather$High )) + \n  labs(subtitle = \"Temperature\", x = \" \", title = \"SFO Weather in 2011\" ) +  theme(plot.title =  element_text(hjust = 0.5))\n\nnormal_record_plt\n\n\n\n\n\n\n\nAdding downward facing triangles and dotted lines\n\nCodelibrary(ggrepel) # for repelling overlap in geom_text \n\n\n# filtering rows which whose record is True\nrec_filtered &lt;-weather %&gt;% \n  filter(Record == TRUE)\n\n\n# adding the months and dashed lines \n# to create the month lines, calculating the mid-points so that the month labels in x axis are in the middle\nmonth_start_dates &lt;- c(1,32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335) \nmidpoints &lt;- (month_start_dates[-length(month_start_dates)] + month_start_dates[-1]) / 2 # \nmonth_centers &lt;-c( 16.5, 46.0, 75.5, 106.0, 136.0, 167.0, 197.5, 228.5, 259.0, 289.5, 320.0, 350)\n\n \n\n# Adding black downward facing triangles and text on plot \n# Used the inherit.aes= False argument so that it geom_text does not inherit previous mappings(error resolved)\n achieved_plt&lt;- normal_record_plt + \n  geom_point(data = rec_filtered, aes(x = rec_filtered$dateInYear, y = rec_filtered$RecordHigh), shape =25,fill = \"black\", inherit.aes = FALSE) +\n   geom_text_repel(\n    data = rec_filtered,\n    aes(x = dateInYear, y = RecordHigh, label = RecordText),size = 1.5, inherit.aes = FALSE ) + \n    labs(x = \"\", y = \"\")\n \n\n \n\n # remocing the x-axis line\n  achieved_plt&lt;- achieved_plt + \n   theme(axis.line.x = element_blank())\n  \n  achieved_plt\n\n\n\n\n\n\n\nCreatting the precipitation plot\n\nCode# precipitation plot \n# triangles area, using geom_area, for blue lines using geom_line, taking only subset of weather data only takes it when record is 1 meaning it makes a record, taking a shape and, color and size\n# geom_text directly puts label on the graph -- very cool! \n\n\n# Month start dates to draw dotted lines and calculating midpoints to center Months\n  month_start_dates &lt;- c(1,32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335) \n  month_centers &lt;-c( 16.5, 46.0, 75.5, 106.0, 136.0, 167.0, 197.5, 228.5, 259.0, 289.5, 320.0, 350) \n  \n# Filtering out Cumulative precipitation for the end of month dates \n  target_dates &lt;- as.Date(c(\n  \"2011-01-31\",\"2011-02-28\",\"2011-03-31\",\"2011-04-30\",\"2011-05-31\",\n  \"2011-06-30\",\"2011-07-31\",\"2011-08-31\",\"2011-09-30\",\"2011-10-31\",\n  \"2011-11-30\",\"2011-12-31\"\n))\n\n  # Creating the column cuml_end_month \nweather &lt;- weather %&gt;%\n  mutate(cuml_end_month = ifelse(date %in% target_dates, CulmPrec, NA))\n\n\n# Creating the precipitation plot \n precip_plt &lt;- ggplot(weather, aes(x= dateInYear, y = CulmPrec)) + theme_classic() +\n  geom_area(fill = \"#ebeae2\") + \n  geom_line(color = \"#32a3d8\") + \n  geom_point(data = subset(weather, RecordP == 1),\n  shape = 25, fill = \"black\", size = 3) + scale_y_continuous(limits = c(0, 8), breaks = c(4,8)) +\n  geom_vline(xintercept =  month_start_dates, color = \"lightgray\")+\n  scale_x_continuous(labels = month.abb, breaks = month_centers, expand = c(0,0)) + labs( subtitle = \"Precipitation\", x = \" \", y = \" \") +    \n   geom_text_repel(\n    data = weather,\n    aes(x = dateInYear, y = CulmPrec,label = cuml_end_month  ), size = 2, inherit.aes = FALSE ) + \n    labs(x = \"\", y = \"\") \n \n \n # removing the x-axis line \n  precip_plt&lt;-precip_plt +\n  theme(axis.line.x = element_blank())\n  precip_plt\n\n\n\n\n\n\n\nArranging both plots together\n\nCode# Arranging both plts \nlibrary(gridExtra)\nplot1 &lt;-achieved_plt\nplot2 &lt;-precip_plt\n\ngrid.arrange(plot1, plot2, heights = c(11, 7.5))",
    "crumbs": [
      "Data Science Projects",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Recreated Original New York Times Graphic visualization</span>"
    ]
  },
  {
    "objectID": "src/pv/pv-01.html#learning-and-reflection",
    "href": "src/pv/pv-01.html#learning-and-reflection",
    "title": "Recreated Original New York Times Graphic visualization",
    "section": "Learning and Reflection",
    "text": "Learning and Reflection\nIn general, I never thought R has the power to create such powerful visualizations, I used think Python and Jave libraries could do it but learnt about some cool R libraries such as ggrepel and gridextra along with the usual ggplot. It was definitely big learning in terms of plotting exact downward triangles, to drawing dotted lines after, centering Months after calculating mid-points and most importatnt solving erorrs of geom_text(). So, building the plot step by step helpmed me learn algorithmic thinking.",
    "crumbs": [
      "Data Science Projects",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Recreated Original New York Times Graphic visualization</span>"
    ]
  },
  {
    "objectID": "src/tt/2025-07-08.html",
    "href": "src/tt/2025-07-08.html",
    "title": "Projects on its way",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Projects on its way</span>"
    ]
  },
  {
    "objectID": "src/tt/2025-07-15.html",
    "href": "src/tt/2025-07-15.html",
    "title": "Projects on its way",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Projects on its way</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html",
    "href": "src/tt/3pm_predict.html",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "",
    "text": "Data Context\nDaily weather observations from multiple locations around Australia, obtained from the Australian Commonwealth Bureau of Meteorology and processed to create this realtively large sample dataset for illustrating analytics, data mining, and data science using R and Rattle.The data has been processed to provide a target variable RainTomorrow (whether there is rain on the following day - No/Yes) and a risk variable RISK_MM (how much rain recorded in millimeters). Various transformations are performed on the data.The weatherAUS dataset is regularly updated an updates of this package usually correspond to updates to this dataset. The data is updated from the Bureau of Meteorology web site.The locationsAUS dataset records the location of each weather station.The source dataset comes from the Australian Commonwealth Bureau of Meteorology. The Bureau provided permission to use the data with the Bureau of Meteorology acknowledged as the source of the data, as per email from Cathy Toby (C.Toby@bom.gov.au) of the Climate Information Services of the National CLimate Centre, 17 Dec 2008.\nYou can download the CSV here for analysis.\nThe weatherAUS dataset is a data frame containing over 140,000 daily observations from over 45 Australian weather stations. Variables include :\nAuthor(s) Graham.Williams@togaware.com\nSource Observations were drawn from numerous weather stations. The daily observations are available from https://www.bom.gov.au/climate/data. Copyright Commonwealth of Australia 2010, Bureau of Meteorology.\nDefinitions adapted from https://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml\nReferences Package home page: https://rattle.togaware.com. Data source: https://www.bom.gov.au/climate/dwo/ and https://www.bom.gov.au/climate/data.",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html#setup",
    "href": "src/tt/3pm_predict.html#setup",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "Setup",
    "text": "Setup\nLoading packages and preping data\n\nCodelibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rattle)\n\ndata(\"weatherAUS\")\nglimpse(weatherAUS)\n## Rows: 208,495\n## Columns: 24\n## $ Date          &lt;date&gt; 2008-12-01, 2008-12-02, 2008-12-03, 2008-12-04, 2008-12…\n## $ Location      &lt;chr&gt; \"Albury\", \"Albury\", \"Albury\", \"Albury\", \"Albury\", \"Albur…\n## $ MinTemp       &lt;dbl&gt; 13.4, 7.4, 12.9, 9.2, 17.5, 14.6, 14.3, 7.7, 9.7, 13.1, …\n## $ MaxTemp       &lt;dbl&gt; 22.9, 25.1, 25.7, 28.0, 32.3, 29.7, 25.0, 26.7, 31.9, 30…\n## $ Rainfall      &lt;dbl&gt; 0.6, 0.0, 0.0, 0.0, 1.0, 0.2, 0.0, 0.0, 0.0, 1.4, 0.0, 2…\n## $ Evaporation   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ Sunshine      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ WindGustDir   &lt;ord&gt; W, WNW, WSW, NE, W, WNW, W, W, NNW, W, N, NNE, W, SW, NA…\n## $ WindGustSpeed &lt;dbl&gt; 44, 44, 46, 24, 41, 56, 50, 35, 80, 28, 30, 31, 61, 44, …\n## $ WindDir9am    &lt;ord&gt; W, NNW, W, SE, ENE, W, SW, SSE, SE, S, SSE, NE, NNW, W, …\n## $ WindDir3pm    &lt;ord&gt; WNW, WSW, WSW, E, NW, W, W, W, NW, SSE, ESE, ENE, NNW, S…\n## $ WindSpeed9am  &lt;dbl&gt; 20, 4, 19, 11, 7, 19, 20, 6, 7, 15, 17, 15, 28, 24, 4, N…\n## $ WindSpeed3pm  &lt;dbl&gt; 24, 22, 26, 9, 20, 24, 24, 17, 28, 11, 6, 13, 28, 20, 30…\n## $ Humidity9am   &lt;int&gt; 71, 44, 38, 45, 82, 55, 49, 48, 42, 58, 48, 89, 76, 65, …\n## $ Humidity3pm   &lt;int&gt; 22, 25, 30, 16, 33, 23, 19, 19, 9, 27, 22, 91, 93, 43, 3…\n## $ Pressure9am   &lt;dbl&gt; 1007.7, 1010.6, 1007.6, 1017.6, 1010.8, 1009.2, 1009.6, …\n## $ Pressure3pm   &lt;dbl&gt; 1007.1, 1007.8, 1008.7, 1012.8, 1006.0, 1005.4, 1008.2, …\n## $ Cloud9am      &lt;int&gt; 8, NA, NA, NA, 7, NA, 1, NA, NA, NA, NA, 8, 8, NA, NA, 0…\n## $ Cloud3pm      &lt;int&gt; NA, NA, 2, NA, 8, NA, NA, NA, NA, NA, NA, 8, 8, 7, NA, N…\n## $ Temp9am       &lt;dbl&gt; 16.9, 17.2, 21.0, 18.1, 17.8, 20.6, 18.1, 16.3, 18.3, 20…\n## $ Temp3pm       &lt;dbl&gt; 21.8, 24.3, 23.2, 26.5, 29.7, 28.9, 24.6, 25.5, 30.2, 28…\n## $ RainToday     &lt;fct&gt; No, No, No, No, No, No, No, No, No, Yes, No, Yes, Yes, Y…\n## $ RISK_MM       &lt;dbl&gt; 0.0, 0.0, 0.0, 1.0, 0.2, 0.0, 0.0, 0.0, 1.4, 0.0, 2.2, 1…\n## $ RainTomorrow  &lt;fct&gt; No, No, No, No, No, No, No, No, Yes, No, Yes, Yes, Yes, …\n\nview(weatherAUS)",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html#data-wrangling-and-visualization",
    "href": "src/tt/3pm_predict.html#data-wrangling-and-visualization",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "Data wrangling and Visualization",
    "text": "Data wrangling and Visualization\nfiltering 6 rows namely : Hobart, Adelaide, Canberra, Brisbane, Melbourne, and Sydney. Mutating(in this case writing over) temp9am values to be farenheit and then selecting the relevant 6 columns\n\nCode\nweather_data &lt;-weatherAUS %&gt;% \n  filter(Location %in% c(\"Hobart\", \"Adelaide\", \"Canberra\", \"Brisbane\", \"Melbourne\", \"Sydney\") ) %&gt;% \n  mutate(Temp9am = Temp9am *1.8 + 32, Temp3pm = Temp3pm * 1.8 + 32) %&gt;% \n  select(Temp3pm, Location, WindSpeed9am, Humidity9am, Pressure9am, \n      Temp9am)\n  \n\n\n\nCode# Checking it out\ndim(weather_data)\n## [1] 26828     6\nhead(weather_data)\n## # A tibble: 6 × 6\n##   Temp3pm Location WindSpeed9am Humidity9am Pressure9am Temp9am\n##     &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;       &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n## 1    69.6 Sydney             17          92       1018.    69.3\n## 2    76.6 Sydney              9          83       1018.    72.3\n## 3    73.4 Sydney             17          88       1017.    74.3\n## 4    69.6 Sydney             22          83       1014.    70.5\n## 5    77.9 Sydney             11          88       1008.    72.5\n## 6    78.8 Sydney              9          69       1003.    74.8\n\n\n\nCode# Arranging it in desending order and then looking at top 3 using head function proving 3 as an argument\ntop_3_hottest &lt;- weather_data %&gt;% \n  arrange(desc(Temp3pm)) %&gt;% \n  head(3)\n\n\n\nCode# checking it out \ntop_3_hottest\n## # A tibble: 3 × 6\n##   Temp3pm Location  WindSpeed9am Humidity9am Pressure9am Temp9am\n##     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;       &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n## 1    117. Adelaide            13          14       1008.    96.4\n## 2    114. Melbourne           54          23       1003.    91.6\n## 3    112. Sydney              13          62       1003.    84.0\n\n\n\nCode# group_by() makes mini groups of every location and then takes mean of the group  based on temp3pm\ntemp3pm_6locs &lt;- weather_data %&gt;% \n  group_by(Location) %&gt;% \n  summarise(mean(Temp3pm, na.rm = TRUE))\n  \n\n\n\nCode# lets check it out \ntemp3pm_6locs\n## # A tibble: 6 × 2\n##   Location  `mean(Temp3pm, na.rm = TRUE)`\n##   &lt;chr&gt;                             &lt;dbl&gt;\n## 1 Adelaide                           70.8\n## 2 Brisbane                           76.7\n## 3 Canberra                           67.0\n## 4 Hobart                             61.2\n## 5 Melbourne                          66.6\n## 6 Sydney                             70.9\n\n\n\nCode# Density plot of temp3p for  6 locations\nggplot(weather_data, aes(x = Temp3pm, fill = Location)) + \n  geom_density(alpha = 0.6) # alpha adds translucency to see overlap\n\n\n\n\n\n\n\n\nCode# creating subplot for each city\n# facet_wrap() -- basically splits one plot into smaller sub plots based on similar values in a column \nggplot(weather_data, aes(x = Temp9am, y = Temp3pm, color = Humidity9am)) + geom_point() + facet_wrap(~Location) +\nscale_color_gradient(low = \"#132B43\", high = \"#56B1F7\")  \n\n\n\n\n\n\n\nInterpreting both the plots.\nInterpretation : Part-d (a) — We’re comparing 3pm temperature of the 6 cities and its variability(how much its varying). Brisbane’s afternoons seems to be in general little hotter relative to other cities as its skewed towards right, higher temp. Similarly Canberra’s afternoons seems pretty cool relative to other cities as its skewed towards left. Apart from the extremes, Hobart, Adeliade and Melbourne seems to have overlap and similar temps more skewed towards cold and sydney seems to have most mid-range temperature of them all.\nInterpretation : Part-d (b) — In this facet’s scatter plot, we’re comparing humidity of 9 am for different cities. We can see that Adelaide show’s linearly decreasing humidity at 9 am when temperatures of 9am and temperatur of 3pm are hotter. So if morning in Adelaide starts warmer and stays warmer till after, then humidity at 9 am, with certain probablity will be lower. Canberra, Hobart, Melbourne, Canberra and Syndey shows stable higher humidty at 9am, and in all of them at the peak warmer tempertures, humidity seems to drop a bit.",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html#mode_1-building",
    "href": "src/tt/3pm_predict.html#mode_1-building",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "Mode_1 Building",
    "text": "Mode_1 Building\n\nCode# Specifying the model\nlm_spec &lt;- linear_reg() |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"lm\")\n\n# checking it out\nlm_spec\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\n\n\nCode# fitting the model\nweather_model_1 &lt;-lm_spec |&gt; \n  fit(Temp3pm ~ Temp9am + Location + Pressure9am, data = weather_data)\n\n\n\nCode# checking it out \nweather_model_1 |&gt; \n  tidy()\n## # A tibble: 8 × 5\n##   term               estimate std.error statistic   p.value\n##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n## 1 (Intercept)       -146.       5.07      -28.8   9.39e-180\n## 2 Temp9am              0.951    0.00404   235.    0        \n## 3 LocationBrisbane    -2.39     0.124     -19.3   2.47e- 82\n## 4 LocationCanberra     3.53     0.123      28.6   2.37e-177\n## 5 LocationHobart      -1.29     0.128     -10.1   3.70e- 24\n## 6 LocationMelbourne   -0.0935   0.123      -0.759 4.48e-  1\n## 7 LocationSydney      -1.12     0.118      -9.43  4.57e- 21\n## 8 Pressure9am          0.154    0.00487    31.8   4.20e-217\n\n\n\nCode# Obtaining the predictions + residuals with augment function as it gives both preidctions and residuals for every row\nweather_model_1 %&gt;% \n  augment(new_data = weather_data) %&gt;% \n  head(10)\n## # A tibble: 10 × 8\n##    .pred .resid Temp3pm Location WindSpeed9am Humidity9am Pressure9am Temp9am\n##    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;       &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n##  1  75.9 -6.29     69.6 Sydney             17          92       1018.    69.3\n##  2  78.9 -2.22     76.6 Sydney              9          83       1018.    72.3\n##  3  80.6 -7.16     73.4 Sydney             17          88       1017.    74.3\n##  4  76.6 -6.96     69.6 Sydney             22          83       1014.    70.5\n##  5  77.5  0.351    77.9 Sydney             11          88       1008.    72.5\n##  6  78.9 -0.108    78.8 Sydney              9          69       1003.    74.8\n##  7  74.7 -2.60     72.1 Sydney             15          75        999     71.1\n##  8  71.4 -1.41     70.0 Sydney              7          77       1008.    66.0\n##  9  68.0 -6.32     61.7 Sydney             19          92       1006.    62.8\n## 10  69.4  4.58     73.9 Sydney             11          80       1014     63.0\n\n\n\nCode# creating the residual plot for weather model 1 \nweather_model_1 %&gt;% \n  augment(new_data = weather_data) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) +\n  geom_point() + \n  geom_hline(yintercept = 0) # coz we want to see where our prediction values fall - below or above 0\n\n\n\n\n\n\n\nIt looks like the model is random, I don’t see any particular shape/ pattern like a slope or parabola etc.This shows that the model is correct as it fits the assumptions of Linear regression. The points seem to be heavily scattered in the middle than tails and there seems to some be outliers but not strong enough to make our model incorrect.\n\nCode# getting the metric to evaluate the model's strength\nweather_model_1 %&gt;% \n  glance()\n## # A tibble: 1 × 12\n##   r.squared adj.r.squared sigma statistic p.value    df  logLik     AIC     BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1     0.757         0.757  5.44    11614.       0     7 -81283. 162584. 162658.\n## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nInterpretaion of the R^2 : The weather_model_1 seems strong as indicated by high R^2 of 0.75687. So the predictor variables – temperature at 9am, Location and pressure at 9am explains approximately 76% of variability in our response varaible – temperature at 3pm. Although it’s not very strong as roughly 24% of variability is still not explained, but in general it seems strong.\n\nCode# cheking the accuracy -- how far my predictions are off \nweather_model_1 %&gt;% \n  augment(new_data = weather_data) %&gt;% \n  summarise(mae = mean(abs(.resid), na.rm = TRUE)) # had to remove the missing values as it was giving mae as na\n## # A tibble: 1 × 1\n##     mae\n##   &lt;dbl&gt;\n## 1  4.24\n\n\nInterpretation of MAE : The mean absolute error is roughly 4, which means that the predictions are off by 4 degrees F for 3pm temperatures. In relative to the scale of the data, which range from 40 degrees F to 120 degress F for 3pm, being 4 degrees F off in range of 80 degrees F (120-40), is 5% (4/80*100). Therefore, the model is 5% off, which means its statistically 95% accourate.\nInterpretation of Temp9am and LocationHobart coefficients :\nTemp9am coefficient interpretation : When controlling for location and pressure at 9am, we expect 3pm temperatures to roughly increase by 0.95 degree F for every 1 degree F increase in 9am temperature.\nLocationHobart interpretation : When controlling for temperature at 9am, pressure at 9 am and other locations, we expect temperature at 3pm in Hobart to be 1.29 degrees F lower than Adelaide on average. ( Adelaide is our reference variable)",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html#model_2-building",
    "href": "src/tt/3pm_predict.html#model_2-building",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "Model_2 Building",
    "text": "Model_2 Building\n\nCode# Fitting Weather_model_2 with all predictor variables\nweather_model_2 &lt;- lm_spec %&gt;% \n   fit(Temp3pm ~ Temp9am + Location + Pressure9am + WindSpeed9am + Humidity9am, data = weather_data)\n\nweather_model_2 %&gt;% \n  tidy()\n## # A tibble: 10 × 5\n##    term              estimate std.error statistic   p.value\n##    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n##  1 (Intercept)       -95.4      5.17       -18.5  1.40e- 75\n##  2 Temp9am             0.898    0.00440    204.   0        \n##  3 LocationBrisbane   -2.17     0.124      -17.5  1.58e- 68\n##  4 LocationCanberra    4.04     0.122       33.1  2.48e-235\n##  5 LocationHobart     -0.471    0.127       -3.72 1.99e-  4\n##  6 LocationMelbourne   1.15     0.125        9.21 3.48e- 20\n##  7 LocationSydney      0.394    0.123        3.20 1.38e-  3\n##  8 Pressure9am         0.113    0.00493     22.9  5.80e-115\n##  9 WindSpeed9am       -0.154    0.00461    -33.4  4.27e-239\n## 10 Humidity9am        -0.0592   0.00244    -24.2  2.24e-128\n\n\n\nCode# Obtaining prediction and residuals for weather_model_2\nweather_model_2 %&gt;% \n  augment(new_data = weather_data) %&gt;% \n  head(10)\n## # A tibble: 10 × 8\n##    .pred .resid Temp3pm Location WindSpeed9am Humidity9am Pressure9am Temp9am\n##    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;       &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n##  1  74.0 -4.43     69.6 Sydney             17          92       1018.    69.3\n##  2  78.6 -1.95     76.6 Sydney              9          83       1018.    72.3\n##  3  78.7 -5.30     73.4 Sydney             17          88       1017.    74.3\n##  4  74.6 -4.94     69.6 Sydney             22          83       1014.    70.5\n##  5  77.1  0.836    77.9 Sydney             11          88       1008.    72.5\n##  6  80.0 -1.17     78.8 Sydney              9          69       1003.    74.8\n##  7  74.9 -2.74     72.1 Sydney             15          75        999     71.1\n##  8  72.5 -2.54     70.0 Sydney              7          77       1008.    66.0\n##  9  66.7 -4.96     61.7 Sydney             19          92       1006.    62.8\n## 10  69.6  4.32     73.9 Sydney             11          80       1014     63.0\n\n\n\nCode# creating the residual plot for weather_model_2\nweather_model_2%&gt;% \n  augment(new_data = weather_data) %&gt;% \n  ggplot(aes(x = .pred, y = .resid)) +\n  geom_point() + \n  geom_hline(yintercept = 0)\n\n\n\n\n\n\n\n\nCode# Looking for R^2 for weather_model2 \nweather_model_2 %&gt;% \n  glance()\n## # A tibble: 1 × 12\n##   r.squared adj.r.squared sigma statistic p.value    df  logLik     AIC     BIC\n##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1     0.769         0.769  5.31     9592.       0     9 -80189. 160400. 160490.\n## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nCode# checking for accuracy \nweather_model_2 %&gt;% \n  augment(new_data = weather_data) %&gt;% \n  summarise(mae = mean(abs(.resid), na.rm = TRUE))\n## # A tibble: 1 × 1\n##     mae\n##   &lt;dbl&gt;\n## 1  4.12\n\n\nInterpretation of Model_1 and Model_2’s strength : As per sample metrics, Model_2 seems to be better than Model_1, although we will check throughly with k-fold validation before accepting it as better",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html#applying-k-fold-cv-validation-algorithm-to-both-models-to-check-for-over-fitting",
    "href": "src/tt/3pm_predict.html#applying-k-fold-cv-validation-algorithm-to-both-models-to-check-for-over-fitting",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "Applying K-fold CV Validation Algorithm to both models to check for over-fitting",
    "text": "Applying K-fold CV Validation Algorithm to both models to check for over-fitting\n\nCode# Conducting the 10 fold cross validation on model_1 \nset.seed(253)\nweather_model_1_cv &lt;- lm_spec %&gt;% \n  fit_resamples(Temp3pm ~ Temp9am + Location + Pressure9am, \n  resamples = vfold_cv(weather_data, v = 10),\n  metrics = metric_set(mae, rsq)\n)\n\nweather_model_1_cv %&gt;% \n  collect_metrics()\n## # A tibble: 2 × 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard   4.25     10 0.0216  pre0_mod0_post0\n## 2 rsq     standard   0.757    10 0.00165 pre0_mod0_post0\n\n\n\nCodeset.seed(253) # setting seed now for reproducibility as k-fold cv algo splits randomly everytime we run code\nweather_model_2_cv &lt;- lm_spec %&gt;% \n  fit_resamples(Temp3pm ~ Temp9am + Location + Pressure9am+ Humidity9am+ WindSpeed9am, \n  resamples = vfold_cv(weather_data, v = 10),\n  metrics = metric_set(mae, rsq)\n)\n\nweather_model_2_cv %&gt;% \n  collect_metrics()\n## # A tibble: 2 × 6\n##   .metric .estimator  mean     n std_err .config        \n##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n## 1 mae     standard   4.12     10 0.0242  pre0_mod0_post0\n## 2 rsq     standard   0.769    10 0.00149 pre0_mod0_post0\n\n\nLets check fold by fold to see if there’s any over-fitting, just to be sure before comparing. Any unusual variance in folds will reveal overfitting\n\nCode# model 1 fold by fold cv\nweather_model_1_cv %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"mae\")\n## # A tibble: 10 × 7\n##    splits               id     .metric .estimator .estimate .config     .notes  \n##    &lt;list&gt;               &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;list&gt;  \n##  1 &lt;split [24145/2683]&gt; Fold01 mae     standard        4.36 pre0_mod0_… &lt;tibble&gt;\n##  2 &lt;split [24145/2683]&gt; Fold02 mae     standard        4.24 pre0_mod0_… &lt;tibble&gt;\n##  3 &lt;split [24145/2683]&gt; Fold03 mae     standard        4.23 pre0_mod0_… &lt;tibble&gt;\n##  4 &lt;split [24145/2683]&gt; Fold04 mae     standard        4.22 pre0_mod0_… &lt;tibble&gt;\n##  5 &lt;split [24145/2683]&gt; Fold05 mae     standard        4.14 pre0_mod0_… &lt;tibble&gt;\n##  6 &lt;split [24145/2683]&gt; Fold06 mae     standard        4.31 pre0_mod0_… &lt;tibble&gt;\n##  7 &lt;split [24145/2683]&gt; Fold07 mae     standard        4.25 pre0_mod0_… &lt;tibble&gt;\n##  8 &lt;split [24145/2683]&gt; Fold08 mae     standard        4.17 pre0_mod0_… &lt;tibble&gt;\n##  9 &lt;split [24146/2682]&gt; Fold09 mae     standard        4.21 pre0_mod0_… &lt;tibble&gt;\n## 10 &lt;split [24146/2682]&gt; Fold10 mae     standard        4.32 pre0_mod0_… &lt;tibble&gt;\n\n\n\nCode# model 2 fold by fold cv\nweather_model_2_cv %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"mae\")\n## # A tibble: 10 × 7\n##    splits               id     .metric .estimator .estimate .config     .notes  \n##    &lt;list&gt;               &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;list&gt;  \n##  1 &lt;split [24145/2683]&gt; Fold01 mae     standard        4.26 pre0_mod0_… &lt;tibble&gt;\n##  2 &lt;split [24145/2683]&gt; Fold02 mae     standard        4.13 pre0_mod0_… &lt;tibble&gt;\n##  3 &lt;split [24145/2683]&gt; Fold03 mae     standard        4.09 pre0_mod0_… &lt;tibble&gt;\n##  4 &lt;split [24145/2683]&gt; Fold04 mae     standard        4.11 pre0_mod0_… &lt;tibble&gt;\n##  5 &lt;split [24145/2683]&gt; Fold05 mae     standard        3.99 pre0_mod0_… &lt;tibble&gt;\n##  6 &lt;split [24145/2683]&gt; Fold06 mae     standard        4.21 pre0_mod0_… &lt;tibble&gt;\n##  7 &lt;split [24145/2683]&gt; Fold07 mae     standard        4.10 pre0_mod0_… &lt;tibble&gt;\n##  8 &lt;split [24145/2683]&gt; Fold08 mae     standard        4.07 pre0_mod0_… &lt;tibble&gt;\n##  9 &lt;split [24146/2682]&gt; Fold09 mae     standard        4.10 pre0_mod0_… &lt;tibble&gt;\n## 10 &lt;split [24146/2682]&gt; Fold10 mae     standard        4.16 pre0_mod0_… &lt;tibble&gt;",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/tt/3pm_predict.html#conclusion",
    "href": "src/tt/3pm_predict.html#conclusion",
    "title": "Forecasting 3 PM Temperatures Across Six Australian Cities",
    "section": "Conclusion",
    "text": "Conclusion\nSo as per the each fold’s mae’s of both weather_model_1 and weather_model_2 shows no overfitting as there’s no extreme fluctuations which shows that both models are generalizing well to unseen data. Comparatively, based on CV metrics, weather_model_2 is better in predicting for 3pm temperatures as it has lower MAE of 4.12 than weather_model_1’s 4.24 MAE and higher R^2 of 0.768 than weather_model_1’s 0.756.",
    "crumbs": [
      "Machine Learning Projects",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forecasting 3 PM Temperatures Across Six Australian Cities</span>"
    ]
  },
  {
    "objectID": "src/ica/ica-sample1.html",
    "href": "src/ica/ica-sample1.html",
    "title": "Portfolio updates coming soon",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Data Engineering Projects",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Portfolio updates coming soon</span>"
    ]
  },
  {
    "objectID": "src/ica/ica-sample2.html",
    "href": "src/ica/ica-sample2.html",
    "title": "Portfolio updates coming soon",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Data Engineering Projects",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Portfolio updates coming soon</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample1.html",
    "href": "src/appx/appx-sample1.html",
    "title": "Appendix A — Coming soon",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Coming soon</span>"
    ]
  },
  {
    "objectID": "src/appx/appx-sample2.html",
    "href": "src/appx/appx-sample2.html",
    "title": "Appendix B — Coming soon",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Coming soon</span>"
    ]
  },
  {
    "objectID": "mm/mm.html",
    "href": "mm/mm.html",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "Creativity",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  },
  {
    "objectID": "mm/mm.html#creativity",
    "href": "mm/mm.html#creativity",
    "title": "Appendix C — Mind Maps",
    "section": "",
    "text": "0808-mind_map_example.jpg",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Mind Maps</span>"
    ]
  }
]